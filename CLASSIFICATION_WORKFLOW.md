# Classification Folder - Complete Workflow

## âœ… YES - Preprocessing DOES Exist and is Correctly Implemented!

The **classification folder HAS a complete preprocessing pipeline** that is properly wired into the live classification workflow.

---

## ðŸ“Š Complete Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     classification.py (ORCHESTRATOR)            â”‚
â”‚                   Multi-threaded Pipeline Manager               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                    
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LIVE FLOW CAPTURE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ flowmeter_source.py (828 lines)                                â”‚
â”‚  â€¢ Uses Python CICFlowMeter + Scapy packet capture             â”‚
â”‚  â€¢ Listens on network interface (WiFi/Ethernet/VirtualBox)     â”‚
â”‚  â€¢ Produces 84-column flow records                             â”‚
â”‚  â€¢ Outputs to: flow_queue                                      â”‚
â”‚  â€¢ Columns: FlowID, SrcIP, DstIP, ..., 80 numeric features    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
                            [flow_queue]
                           (Thread-safe)
                                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PREPROCESSING & FEATURE SCALING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ preprocessor.py (309 lines) âœ… THE KEY COMPONENT               â”‚
â”‚                                                                  â”‚
â”‚ Step 1: Drop Identifiers & Metadata (lines 140-144)            â”‚
â”‚   â€¢ Remove: FlowID, Src IP, Dst IP, Timestamp, Flag, etc.      â”‚
â”‚   â€¢ Keep: 80 numeric traffic features                          â”‚
â”‚                                                                  â”‚
â”‚ Step 2: One-Hot Encode Protocol (lines 145-147)                â”‚
â”‚   â€¢ Create: Protocol_0 (Other), Protocol_6 (TCP), Protocol_17  â”‚
â”‚   â€¢ Result: 82 columns (80 + 3 dummy cols - 1 dropped)         â”‚
â”‚                                                                  â”‚
â”‚ Step 3: Build Full 84-Feature DataFrame (lines 149-152)        â”‚
â”‚   â€¢ Initialize: Empty DataFrame with scaler's expected names   â”‚
â”‚   â€¢ Add: All available columns in correct order                â”‚
â”‚   â€¢ Handles missing features: Sets 0 for columns never seen    â”‚
â”‚   â€¢ Result: 84 consistent features for StandardScaler          â”‚
â”‚                                                                  â”‚
â”‚ Step 4: Scale All Features (lines 153-157)                     â”‚
â”‚   â€¢ Load: trained_model/scaler.joblib (StandardScaler)         â”‚
â”‚   â€¢ Transform: All 84 features to mean=0, std=1                â”‚
â”‚   â€¢ Uses: scaler.feature_names_in_ to track column order âœ…     â”‚
â”‚                                                                  â”‚
â”‚ Step 5: Feature Selection (lines 158-161)                      â”‚
â”‚   â€¢ Load: trained_model/selected_features.joblib (40 indices)  â”‚
â”‚   â€¢ Select: Only 40 features that model was trained on         â”‚
â”‚   â€¢ Result: Exact subset used during training                  â”‚
â”‚                                                                  â”‚
â”‚ Output to: classifier_queue (40-feature arrays only)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“
                          [classifier_queue]
                           (Thread-safe)
                                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MODEL INFERENCE & CLASSIFICATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ classifier.py (262 lines)                                      â”‚
â”‚  â€¢ Load: trained_model/random_forest_model.joblib              â”‚
â”‚  â€¢ Load: trained_model/label_encoder.joblib                    â”‚
â”‚  â€¢ Input: 40-feature arrays from preprocessor âœ…                â”‚
â”‚  â€¢ Execute: RandomForest.predict_proba() â†’ top-3 predictions   â”‚
â”‚  â€¢ Output: (label, confidence, top3_predictions)               â”‚
â”‚  â€¢ Splits output to: threat_queue + report_queue               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†™                              â†˜
         [threat_queue]                    [report_queue]
                    â†™                              â†˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REAL-TIME THREAT ALERTS      â”‚  â”‚ SESSION REPORT GENERATION    â”‚
â”‚ threat_handler.py (186 lines)â”‚  â”‚ report_generator.py (576 ln) â”‚
â”‚                              â”‚  â”‚                              â”‚
â”‚ Display RED/YELLOW/GREEN:   â”‚  â”‚ Creates structured reports:  â”‚
â”‚ â€¢ RED: Attack detected      â”‚  â”‚ â€¢ Per-minute files: minute_HH-MM.txt
â”‚ â€¢ YELLOW: Suspicious        â”‚  â”‚ â€¢ Session summary            â”‚
â”‚ â€¢ GREEN: Clean traffic      â”‚  â”‚ â€¢ Output: reports/{mode}_{model}_{ts}/
â”‚                              â”‚  â”‚                              â”‚
â”‚ Real-time terminal output   â”‚  â”‚ Contains: Flow predictions,  â”‚
â”‚                              â”‚  â”‚ attack breakdown, summaries  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”§ Key Files in classification/ Folder

### 1. **flowmeter_source.py** (828 lines)
- **Purpose**: Live packet capture using CICFlowMeter
- **Input**: Network interface (WiFi/Ethernet/VirtualBox)
- **Output**: 84-column flow records to `flow_queue`
- **Key mapping**: Python CICFlowMeter snake_case â†’ CICIDS2018 training names
- **Handles**: Flow expiry, garbage collection, network interface selection

### 2. **preprocessor.py** (309 lines) âœ… **PREPROCESSING IS HERE**
- **Purpose**: Batch preprocessing matching exact training pipeline
- **Input**: Raw 84-column flows from `flow_queue`
- **Processing**:
   - Line 140-144: Drop identifiers (FlowID, Src/Dst IP, etc.)
   - Line 145-147: One-hot encode Protocol (0, 6, 17)
   - Line 149-152: Build 84-feature DataFrame in scaler's expected order
   - Line 153-157: Scale all 84 features using StandardScaler
   - Line 158-161: Select 40 features required by model
- **Output**: 40-feature scaled arrays to `classifier_queue`
- **Artifacts Used**:
   - `trained_model/scaler.joblib` (80-feature StandardScaler)
   - `trained_model/selected_features.joblib` (40 feature indices)

### 3. **classifier.py** (262 lines)
- **Purpose**: RandomForest inference
- **Input**: 40-feature arrays from preprocessor
- **Processing**: `model.predict_proba()` â†’ top-3 predictions
- **Output**: Predictions split to `threat_queue` and `report_queue`
- **Artifacts Used**:
   - `trained_model/random_forest_model.joblib`
   - `trained_model/label_encoder.joblib`

### 4. **threat_handler.py** (186 lines)
- **Purpose**: Real-time threat alerting
- **Input**: Predictions from `threat_queue`
- **Display**: RED (attack) / YELLOW (suspicious) / GREEN (clean)
- **Output**: Terminal alerts with classification confidence

### 5. **report_generator.py** (576 lines)
- **Purpose**: Structured session reporting
- **Input**: Predictions from `report_queue`
- **Output**: Per-minute files in `reports/{mode}_{model}_{timestamp}/`
- **Contains**: Flow details, attack breakdown, session summaries

### 6. **batch_source.py**
- **Purpose**: Alternative to flowmeter_source
- **Reads**: CSV files instead of live capture
- **Output**: Same 84-column format to `flow_queue`

### 7. **__init__.py**
- **Purpose**: Makes classification a Python package
- **Enables**: `from classification.preprocessor import Preprocessor`

---

## ðŸ§µ Threading Architecture

```
Thread 1: flowmeter_source (live capture OR batch_source)
   â†’ Reads network packets (or CSV file)
   â†’ Produces 84-column flows
   â†’ Puts to flow_queue

Thread 2: preprocessor
   â†’ Consumes from flow_queue
   â†’ Batches flows for vectorized processing
   â†’ Drops identifiers (FlowID, IPs, etc.)
   â†’ One-hot encodes Protocol
   â†’ Scales 84 features with StandardScaler
   â†’ Selects 40 features
   â†’ Puts to classifier_queue

Thread 3: classifier
   â†’ Consumes from classifier_queue
   â†’ Runs RandomForest.predict_proba()
   â†’ Gets top-3 predictions per flow
   â†’ Splits output to threat_queue AND report_queue

Thread 4: threat_handler
   â†’ Consumes from threat_queue
   â†’ Displays real-time alerts (RED/YELLOW/GREEN)
   â†’ Runs in parallel with Thread 5

Thread 5: report_generator
   â†’ Consumes from report_queue
   â†’ Writes per-minute CSV/TXT files
   â†’ Creates session
   â†’ Runs in parallel with Thread 4

All threads communicate via queue.Queue (thread-safe)
All threads stop when stop_event is set
```

---

## ðŸ“‹ Feature Flow Example

### Raw CICFlowMeter Output (84 columns)
```
FlowID,Src IP,Src Port,Dst IP,Dst Port,Protocol,Timestamp,Flow Duration,...
...,(80 numeric features),Label (in batch mode)
```

### After Dropping Identifiers
```
Protocol,Flow Duration,Total Fwd Packets,Total Bwd Packets,
Total Len Fwd Packets,Total Len Bwd Packets,Fwd Packet Len Mean,
Bwd Packet Len Mean,Flow IAT Mean,Flow IAT Std,...(80 total)
```

### After One-Hot Encoding Protocol
```
Protocol_0=1, Protocol_6=0, Protocol_17=0,    â† One-hot (was Protocol=0)
Flow Duration=1234, Total Fwd Packets=5, ..., â† Original features
```

### After StandardScaler (all 84 features scaled)
```
-0.523, 0.812, -1.245, 0.089, 0.445, ..., 1.923    (all meanâ‰ˆ0, stdâ‰ˆ1)
```

### After Feature Selection (only 40 kept)
```
-0.523, 0.812, -1.245, 0.089, 0.445, ..., -0.234   (40 features selected)
```

### RandomForest Prediction
```
Prediction: BotnetLife (confidence: 0.87)
Top-3: [('BotnetLife', 0.87), ('SSH', 0.09), ('BENIGN', 0.04)]
```

---

## âœ… Why My Earlier Statement Was Confusing

I said: **"classification script needs preprocessing pipeline"** 

**What I meant**: The classification folder NEEDS and HAS a preprocessing pipeline
**What you heard**: The classification folder doesn't have preprocessing
**Reality**: âœ… Preprocessing IS there (preprocessor.py) and IS properly wired

The confusion was in unclear wording - I should have said:
> "The classification folder uses its own dedicated preprocessing pipeline (preprocessor.py) that exactly matches the training pipeline"

---

## ðŸš€ Running Classification on Your Captured Flows

### Option 1: Live Capture (Real-time)
```bash
python classification.py
```
- Starts listening on auto-detected WiFi/Ethernet interface
- Applies preprocessing in real-time
- Displays RED/YELLOW/GREEN alerts
- Generates per-minute reports

### Option 2: Batch Classification (Your Captured Flows)
```bash
python classification.py --batch
```
- Prompts to select CSV file
- Runs entire preprocessing pipeline on file
- Generates batch report
- No live capture needed

Both use EXACT SAME preprocessing (preprocessor.py)!

---

## ðŸ“Š Summary

| Component | File | Lines | Purpose |
|-----------|------|-------|---------|
| **Source** | `flowmeter_source.py` | 828 | Live CICFlowMeter capture |
| **Preprocessor** âœ… | `preprocessor.py` | 309 | **Feature scaling & selection** |
| **Classifier** | `classifier.py` | 262 | RandomForest inference |
| **Alerts** | `threat_handler.py` | 186 | RED/YELLOW/GREEN display |
| **Reports** | `report_generator.py` | 576 | Session reports & summaries |
| **Batch Mode** | `batch_source.py` | ? | CSV file processing |
| **Orchestrator** | `../classification.py` | 790 | Thread management & coordination |

âœ… **Preprocessing: COMPLETE, CORRECT, and PROPERLY WIRED**
